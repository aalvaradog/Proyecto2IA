{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1lRCShc9A5aRpB2ZYI4q9SW0kzZecGYJv",
      "authorship_tag": "ABX9TyNMV563SD8Hh5g+7W2wHmMR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalvaradog/Proyecto2IA/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Comprobar si hay una GPU disponible\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Si hay una GPU disponible, configurar TensorFlow para usarla\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    # Configurar TensorFlow para utilizar la GPU\n",
        "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "xtO1-X0y1ywR",
        "outputId": "e49ecd2a-beb9-4d73-e9f2-60951dfa9381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Physical devices cannot be modified after being initialized",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-afa6d7029125>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Configurar TensorFlow para utilizar la GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m   \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m       raise RuntimeError(\n\u001b[0m\u001b[1;32m   1783\u001b[0m           \"Physical devices cannot be modified after being initialized\")\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Cargar el modelo pre-entrenado VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Congelar las capas convolucionales para que los pesos no se actualicen durante el entrenamiento\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Agregar capas personalizadas para la clasificación\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Cargar y preprocesar datos\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-esGU-57Uwr",
        "outputId": "ba0f67da-c4d9-4771-a741-9fd027c3b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3583 - accuracy: 0.5239 - val_loss: 1.2408 - val_accuracy: 0.5660\n",
            "Epoch 2/5\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1764 - accuracy: 0.5896 - val_loss: 1.1608 - val_accuracy: 0.5974\n",
            "Epoch 3/5\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1113 - accuracy: 0.6091 - val_loss: 1.1192 - val_accuracy: 0.6038\n",
            "Epoch 4/5\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0616 - accuracy: 0.6280 - val_loss: 1.0870 - val_accuracy: 0.6242\n",
            "Epoch 5/5\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0155 - accuracy: 0.6466 - val_loss: 1.1060 - val_accuracy: 0.6112\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1434 - accuracy: 0.6023\n",
            "Accuracy: 0.6022999882698059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos crudos"
      ],
      "metadata": {
        "id": "2gE_TLCj3qgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras.utils\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Cargar el modelo pre-entrenado VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Congelar las capas convolucionales para que los pesos no se actualicen durante el entrenamiento\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Agregar capas personalizadas para la clasificación\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "# Definir la ruta de la carpeta que contiene las imágenes\n",
        "folder_path = '/content/drive/MyDrive/DatosIA/Data/raw/training_set'\n",
        "# Listar todas las carpetas en la ruta especificada\n",
        "subfolders = os.listdir(folder_path)\n",
        "\n",
        "# Listas para almacenar las imágenes y las etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar las imágenes y las etiquetas\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, file)\n",
        "        image = load_img(image_path, target_size=(32, 32))\n",
        "        image = img_to_array(image) / 255.0  # Normalizar la imagen\n",
        "        images.append(image)\n",
        "        labels.append(subfolder)\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "img_training = np.array(images)\n",
        "labels_training = np.array(labels)\n",
        "\n",
        "# Definir la ruta de la carpeta que contiene las imágenes\n",
        "folder_path = '/content/drive/MyDrive/DatosIA/Data/raw/test_set'\n",
        "# Listar todas las carpetas en la ruta especificada\n",
        "subfolders = os.listdir(folder_path)\n",
        "\n",
        "# Listas para almacenar las imágenes y las etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar las imágenes y las etiquetas\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, file)\n",
        "        image = load_img(image_path, target_size=(32, 32))\n",
        "        image = img_to_array(image) / 255.0  # Normalizar la imagen\n",
        "        images.append(image)\n",
        "        labels.append(subfolder)\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "img_testing = np.array(images)\n",
        "labels_testing = np.array(labels)\n",
        "\n",
        "# Inicializar el LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar el LabelEncoder a las etiquetas y transformarlas en números\n",
        "encoded_train = label_encoder.fit_transform(labels_training)\n",
        "\n",
        "# Ajustar el LabelEncoder a las etiquetas y transformarlas en números\n",
        "encoded_test = label_encoder.fit_transform(labels_testing)\n",
        "\n",
        "# Mapeo de las etiquetas a los números\n",
        "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "\n",
        "# One-hot encode the target arrays\n",
        "y_train_onehot = keras.utils.to_categorical(encoded_train, num_classes=3)\n",
        "y_test_onehot = keras.utils.to_categorical(encoded_test, num_classes=3)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(img_training, y_train_onehot, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(img_testing, y_test_onehot)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "MvtRp6T9LMCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9349a53-6751-4e45-a33f-34deeb2d960d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 30ms/step - loss: 0.7536 - accuracy: 0.6485 - val_loss: 0.5148 - val_accuracy: 0.8070\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.4551 - accuracy: 0.8279 - val_loss: 0.2420 - val_accuracy: 0.9006\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3731 - accuracy: 0.8544 - val_loss: 0.2149 - val_accuracy: 0.9123\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3010 - accuracy: 0.9000 - val_loss: 0.2010 - val_accuracy: 0.9240\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.9074 - val_loss: 0.3775 - val_accuracy: 0.8713\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.8502\n",
            "Accuracy: 0.8501529097557068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos con filtro bilateral"
      ],
      "metadata": {
        "id": "qMGWU_BX-9j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras.utils\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Cargar el modelo pre-entrenado VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Congelar las capas convolucionales para que los pesos no se actualicen durante el entrenamiento\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Agregar capas personalizadas para la clasificación\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "# Definir la ruta de la carpeta que contiene las imágenes\n",
        "folder_path = '/content/drive/MyDrive/DatosIA/Data/bilateralFilter/training_set'\n",
        "# Listar todas las carpetas en la ruta especificada\n",
        "subfolders = os.listdir(folder_path)\n",
        "\n",
        "# Listas para almacenar las imágenes y las etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar las imágenes y las etiquetas\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, file)\n",
        "        image = load_img(image_path, target_size=(32, 32))\n",
        "        image = img_to_array(image) / 255.0  # Normalizar la imagen\n",
        "        images.append(image)\n",
        "        labels.append(subfolder)\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "img_training = np.array(images)\n",
        "labels_training = np.array(labels)\n",
        "\n",
        "# Definir la ruta de la carpeta que contiene las imágenes\n",
        "folder_path = '/content/drive/MyDrive/DatosIA/Data/bilateralFilter/test_set'\n",
        "# Listar todas las carpetas en la ruta especificada\n",
        "subfolders = os.listdir(folder_path)\n",
        "\n",
        "# Listas para almacenar las imágenes y las etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar las imágenes y las etiquetas\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, file)\n",
        "        image = load_img(image_path, target_size=(32, 32))\n",
        "        image = img_to_array(image) / 255.0  # Normalizar la imagen\n",
        "        images.append(image)\n",
        "        labels.append(subfolder)\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "img_testing = np.array(images)\n",
        "labels_testing = np.array(labels)\n",
        "\n",
        "# Inicializar el LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar el LabelEncoder a las etiquetas y transformarlas en números\n",
        "encoded_train = label_encoder.fit_transform(labels_training)\n",
        "\n",
        "# Ajustar el LabelEncoder a las etiquetas y transformarlas en números\n",
        "encoded_test = label_encoder.fit_transform(labels_testing)\n",
        "\n",
        "# Mapeo de las etiquetas a los números\n",
        "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "\n",
        "# One-hot encode the target arrays\n",
        "y_train_onehot = keras.utils.to_categorical(encoded_train, num_classes=3)\n",
        "y_test_onehot = keras.utils.to_categorical(encoded_test, num_classes=3)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(img_training, y_train_onehot, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(img_testing, y_test_onehot)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJobwv81_DrZ",
        "outputId": "640a8d2a-2530-4a1a-d652-e99ca943f8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "26/26 [==============================] - 2s 25ms/step - loss: 0.7334 - accuracy: 0.6928 - val_loss: 0.9113 - val_accuracy: 0.6617\n",
            "Epoch 2/5\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.4159 - accuracy: 0.8520 - val_loss: 0.7325 - val_accuracy: 0.7512\n",
            "Epoch 3/5\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.3197 - accuracy: 0.8968 - val_loss: 0.6929 - val_accuracy: 0.7562\n",
            "Epoch 4/5\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.2793 - accuracy: 0.9092 - val_loss: 0.7267 - val_accuracy: 0.7512\n",
            "Epoch 5/5\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.2310 - accuracy: 0.9279 - val_loss: 0.6275 - val_accuracy: 0.7662\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8409\n",
            "Accuracy: 0.8409090638160706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos con filtro canny"
      ],
      "metadata": {
        "id": "I-36LHzRBtYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras.utils\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Cargar el modelo pre-entrenado VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Congelar las capas convolucionales para que los pesos no se actualicen durante el entrenamiento\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Agregar capas personalizadas para la clasificación\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "# Definir la ruta de la carpeta que contiene las imágenes\n",
        "folder_path = '/content/drive/MyDrive/DatosIA/Data/cannyFilter/training_set'\n",
        "# Listar todas las carpetas en la ruta especificada\n",
        "subfolders = os.listdir(folder_path)\n",
        "\n",
        "# Listas para almacenar las imágenes y las etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar las imágenes y las etiquetas\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, file)\n",
        "        image = load_img(image_path, target_size=(32, 32))\n",
        "        image = img_to_array(image) / 255.0  # Normalizar la imagen\n",
        "        images.append(image)\n",
        "        labels.append(subfolder)\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "img_training = np.array(images)\n",
        "labels_training = np.array(labels)\n",
        "\n",
        "# Definir la ruta de la carpeta que contiene las imágenes\n",
        "folder_path = '/content/drive/MyDrive/DatosIA/Data/cannyFilter/test_set'\n",
        "# Listar todas las carpetas en la ruta especificada\n",
        "subfolders = os.listdir(folder_path)\n",
        "\n",
        "# Listas para almacenar las imágenes y las etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar las imágenes y las etiquetas\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, file)\n",
        "        image = load_img(image_path, target_size=(32, 32))\n",
        "        image = img_to_array(image) / 255.0  # Normalizar la imagen\n",
        "        images.append(image)\n",
        "        labels.append(subfolder)\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "img_testing = np.array(images)\n",
        "labels_testing = np.array(labels)\n",
        "\n",
        "# Inicializar el LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar el LabelEncoder a las etiquetas y transformarlas en números\n",
        "encoded_train = label_encoder.fit_transform(labels_training)\n",
        "\n",
        "# Ajustar el LabelEncoder a las etiquetas y transformarlas en números\n",
        "encoded_test = label_encoder.fit_transform(labels_testing)\n",
        "\n",
        "# Mapeo de las etiquetas a los números\n",
        "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "\n",
        "# One-hot encode the target arrays\n",
        "y_train_onehot = keras.utils.to_categorical(encoded_train, num_classes=3)\n",
        "y_test_onehot = keras.utils.to_categorical(encoded_test, num_classes=3)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(img_training, y_train_onehot, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(img_testing, y_test_onehot)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOQ8P7AGBx2s",
        "outputId": "2d094503-9ea0-4194-f3c5-469eeb2bcbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 57ms/step - loss: 0.4140 - accuracy: 0.8246 - val_loss: 5.7300 - val_accuracy: 0.0345\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.2075 - accuracy: 0.9561 - val_loss: 7.2505 - val_accuracy: 0.0345\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1523 - accuracy: 0.9561 - val_loss: 7.1563 - val_accuracy: 0.0345\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0878 - accuracy: 0.9693 - val_loss: 6.9998 - val_accuracy: 0.0345\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0803 - accuracy: 0.9781 - val_loss: 7.4624 - val_accuracy: 0.0345\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.5788 - accuracy: 0.3653\n",
            "Accuracy: 0.3652849793434143\n"
          ]
        }
      ]
    }
  ]
}