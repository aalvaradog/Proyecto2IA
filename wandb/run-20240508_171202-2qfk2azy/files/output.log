
Epoch: 1  Train Loss: 0.4748  Train Acc: 80.2789  Valid Loss: 0.5987  Valid Acc: 70.9596
Epoch: 2  Train Loss: 0.1706  Train Acc: 93.4263  Valid Loss: 0.5081  Valid Acc: 77.2727
Epoch: 3  Train Loss: 0.1040  Train Acc: 96.3479  Valid Loss: 0.5753  Valid Acc: 84.0909
Epoch: 4  Train Loss: 0.0572  Train Acc: 97.8088  Valid Loss: 0.5071  Valid Acc: 83.3333
Epoch: 5  Train Loss: 0.0320  Train Acc: 99.1368  Valid Loss: 0.4398  Valid Acc: 88.3838
Epoch: 6  Train Loss: 0.0222  Train Acc: 99.2696  Valid Loss: 0.3921  Valid Acc: 88.6364
Epoch: 7  Train Loss: 0.0122  Train Acc: 99.8008  Valid Loss: 0.4868  Valid Acc: 87.8788
Epoch: 8  Train Loss: 0.0137  Train Acc: 99.5352  Valid Loss: 0.4786  Valid Acc: 87.8788
Epoch: 9  Train Loss: 0.0022  Train Acc: 100.0000  Valid Loss: 0.5406  Valid Acc: 88.8889
Epoch: 10  Train Loss: 0.0004  Train Acc: 100.0000  Valid Loss: 0.5197  Valid Acc: 88.3838
Total samples: 1506
Batch size: 32
Number of batches per epoch: 48
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.